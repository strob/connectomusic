connectomusic
--

a graph-based neurally-inspired composition suite.

working with historical images in augmented UI (digitize.py,
qDrawGraph.py), we create digital graph representations from bitmap
images. nodes are encoded with their x,y position and edges assume a
cost equal to their spatial distance.

a suite of samples are assigned to nodes based on the total number of
outbound edges, and when a node ``fires,'' it both plays whatever
sample is associated and releases (in time proportional to distance)
neighboring nodes for attenuated triggering.

## Rules

* Edges are directed and flow from nodes with more edges to those with fewer, unless flipped, F.

* Assign letter-sounds to graph-nodes by number of connecting edges.

* After playing a sample, send a pulse down all outgoing edges at speed S.

* Nodes without sounds assigned are regulation nodes; they suppress signal when active nodes exceed target T.

* Looping nodes repeat after playback, unless target T is met.

## Spec

A piece, then, can be described by initial conditions:

  { F: (1|0),
    S: (0,1000),
    T: (0,1000),
    trigger: [node, [node, ...]] }